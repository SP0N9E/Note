# 数字视音频复习

[TOC]

## 音乐

### 音乐的基本要素

音高（频率）、音强（振幅）、音长（时值）、音色（发声体谐波特性）

计算机表示方法：

![1](.\img\1.jpg)

### 音乐的制作流程

作词作曲，编曲，录音，混音

### 音乐合成技术

1. **软件**

   overture

   SONAR

   Adobe Audition

2. **语言编程**

   1. 基于Nyquist的音乐合成（lisp，基本声音的合成），OpenAL（三维音效），Matlab， Flash Action Script

   ![2](.\img\2.jpg)

   ![3](.\img\3.jpg)

3. 更倾向于音乐艺术与软件工程的结合

   - 创意
   - 协作
   - 软件/语言的使用

   

### 音乐分析

#### 表现形式

- 节奏：组织起来的音的长短关系
- 旋律：长短，高低，强弱不同的一连串乐音有组织的进行
- 和声：和弦（三个或以上乐音组合） + 和声进行（和弦的横向组织）

#### 节奏识别

**框架：**

![4](.\img\4.png)

**特征提取方式：**时域分析、频域分析



#### 音准评分

1. 旋律评分模块：求取演唱者演唱旋律，并与歌曲原旋律对比，匹配越好给分越高
2. 抢拍与慢拍分析模块：分析演唱者抢拍与慢拍情况，并酌情给予减分
3. 节奏分析模块：分析演唱者的节奏感是否与歌曲的节奏一致，节奏感越好给分越多
4. 演唱情绪分析模块：分析演唱者演唱的情绪，如果演唱者演唱的情绪与歌曲的意境相符，会有相应的加分
5. 声音圆润饱满度分析模块：分析演唱者演唱的声音是否圆润，是否饱满，越圆润越饱满给分越多
6. 语音识别模块：分析演唱者演唱的歌词是否与歌曲的歌词相符，错误率越少给分赵多



### 音乐检索

#### 乐纹检索

1. 框架：

   ![5](.\img\5.png)

   频域分析$\rightarrow$通过特征点对索引技术构建乐纹库$\rightarrow$三重链表查询

2. 乐纹概念与特性

   **概念：**可以代表一段音乐重要声学特征的基于内容的紧致数字签名

   **特性：**鲁棒性、区分性

   ​	



#### 哼唱检索

1. 框架：

   ![6](.\img\6.png)

   ![7](.\img\7.jpg)

   

2. 旋律表示：三层表示

   - 在最低的声学层上，哼唱的旋律经过基频提取，被表示为基于帧的音高序列
   - 在较高的符号层（或音符层）上，系统综合基频曲线、谐波和能量等信息，将基频序列切分成格式化的音符序列；
   - 最后，系统将在乐句的层次上寻找旋律中的轮廓点，并试图确定数据库中的旋律乐句边界

3. 旋律特征提取

   基频提取、音符切分、轮廓点提取等各级旋律提取结果

4. 旋律查询

   基于轮廓因子索引的快速检索法 midomi公司



## 视频

### 视频数据压缩

#### 无损压缩与有损压缩

- 无损压缩：压缩的数据和原始数据完全一样。
- 有损压缩：压缩的数据和原始数据不相同，但非常相近。





### 视频结构化与非线性编辑部分

#### 镜头检测

​	镜头是视频流数据的最小物理数据单元，所谓镜头检测就是给定有n个镜头的视频V，找到每个镜头的开始和结尾部分。也被称作边界检测（boundary detection）或转换检测（transition detection）。

#### 镜头边缘检测算法的实质及核心问题

​	**实质：**找到一种或几种良好的视频图像**特征**，通过判断相邻图像帧之间的特征是否发生**剧烈变化**，来完成视频镜头边缘检测任务。

​    **核心问题**：如何选择特征，如何定义相似度函数

​     **//或者是关键问题：**(1) 自适应阈值 (2)渐变镜头数学模型

#### 视频结构化

帧（frame）：帧是视频流中的基本组成单元

镜头（shot）：摄像机拍下的不间断帧序列，是视频数据流进一步结构化的基础结构层。

关键帧（key frame）：关键帧是可以用来代表镜头内容的图像

场景（scene）：语义上相关和时间上相邻的若干组镜头组成了一个场景，场景是视频所蕴涵的高层抽象概念和语义的表达

组（group）：组是介于物理镜头和语义场景之间的结构。

![8](.\img\8.jpg)



#### 视频结构化分析包含哪些基本步骤、内容（又：视频目录生成构造的主要步骤

-  镜头边缘检测

-  关键帧提取

-  时空特征提取

-  时间可适性成组

-  场景结构构造



#### 镜头时间特征和空间特征的区别

**镜头时间特征**：包含运动信息，即镜头中前后两帧的差异累积

是基于镜头中所有视频帧得到的

![img](https://img-blog.csdn.net/20170106010702933)

 **镜头空间特征**：

基于镜头中的关键帧得到的

![img](https://img-blog.csdn.net/20170106010749605)



#### 镜头边缘检测算法

##### 绝对帧间差法

- 判断相邻图像帧之间特征的绝对差是否大

- 具体实现时，判断两个相邻帧差别的方法可以是：计算相邻两个图像帧中所有像素的色彩亮度之和，两帧的差别就定义为各自对应像素的亮度和之差

##### 图像像素差法

- 首先统计两幅图像对应像素变化超过阈值的像素点个数。
- 然后，将变化的像素点个数与第二个预定的阈值比较，如超过范围，则认为这两帧之间发生较大变化，判断其为镜头边界
- 但该法对镜头移动十分敏感，对噪声的容错性较差。

##### 图像数值差法

- 将图像分成若干个子块区域，在这些区域中分别比较对应像素数值上的差别。

##### 颜色直方图法

- 通过直方图差度量

  <img src=".\img\9.jpg" alt="9"  />

- 通过带权重的直方图差

  ![10](.\img\10.jpg)

- 直方图的交

  ![11](.\img\11.jpg)



##### 压缩域差法

![12](.\img\12.jpg)

##### 矩不变量法

![13](.\img\13.jpg)

![14](.\img\14.jpg)



##### 边界跟踪法

![15](.\img\15.jpg)

##### 运动矢量法

![16](.\img\16.jpg)



#### 渐变镜头的数学模型

**Dissolve的数学模型**

f(x,y)场景A  

g(x,y)  场景B 

L1：场景A持续时间

L2：场景B持续时间

F：场景A,B Dissolve持续时间

![img](https://img-blog.csdn.net/20170112132609512)

均值：![img](https://img-blog.csdn.net/20170112133704408)

方差：

![17](.\img\17.jpg)

#### 关键帧提取算法

##### 基于镜头边界法

将切分得到镜头中的第一幅图像和最后一幅图像作为镜头关键帧

##### 基于特征转变法

- 在基于视频图像特征提取关键帧方法中，镜头当前帧与最后一个判断为关键帧的图像比较，如有较多特征发生改变，则当前帧为新的一个关键帧。

##### 基于运动分析法

- 在这种方法中，将相机运动造成的图像变化分成两类

1. 由相机焦距变化造成: 选择首、尾两帧为关键帧；
2. 由相机角度变化造成: 如当前帧与上一关键帧重叠小于30%，则选其为关键帧；

##### 基于聚类的关键帧提取

​	常用K-means。求帧与质心距离，距离大形成新的聚类，否则加入原有聚类；每次计算后都更新质心；非监督过程。



#### 时间可适性组构造

- 实际上就是**镜头成组过程**，是视频目录结构生成过程中的第四步

- 在构造场景结构之前，先用得到的镜头信息构建一个结构，这个结构称为“组（group）”，每个组里包含相似的镜头。

##### 镜头相似

1. **视觉相似性：**相似镜头在视觉上是相似的，也就是具有相似的空间特征（颜色直方图等）。
2. **时间局部性：**相似镜头在时间上会尽可能接近。视觉上相似的镜头如果在时间上相差很远，就不太可能属于同一场景，因此也不属于同一组。

##### 时间可适性成组法

1. 先计算镜头间的颜色相似度（空间特征）

   ![18](.\img\18.jpg)

   ![19](.\img\19.jpg)

   ![20](.\img\20.jpg)

   ![21](.\img\21.jpg)

   

2. 再计算镜头间的运动相似度（时间特征）

   ![22](.\img\22.jpg)

   

3. 最后计算总相似度

   ![23](.\img\23.jpg)

   



#### 视频场景构造（镜头成组过程）

- 是视频目录生成中的第五步
- 不仅计算当前镜头和组的相似度，而且计算当前镜头和包含所有组的场景的相似度。因为不相似的组在语义上相关也可以组合到同一个场景中，例如两个人互相交谈的过程。

##### 算法描述

**输入：** 视频镜头序列，$S‘={Shot_0,…,Shot_i}$

**输出：**含有场景、组和镜头的视频结构

![24](.\img\24.jpg)

![25](.\img\25.jpg)

![26](.\img\26.jpg)

**函数说明：**findGroupSim把相似的镜头组合到一个组中，findSceneSim把镜头（或者仅包含一个镜头的组）组合到场景中；然后，updateGroupScene和updateScene把语义上相关的镜头组合到同一场景。



#### 视频时序结构图构造

**步骤：**

- 视频解码
- 视频切分
- 关键帧提取
- 视频聚类分析
- 构造时序图
- 按照时序图浏览

**构造方法：**

<img src=".\img\27.jpg" alt="27" style="zoom:80%;" />

<img src=".\img\28.jpg" alt="28" style="zoom: 67%;" />

![29](.\img\29.jpg)



#### 视频例子的相似匹配

常用弹性度量算法，本质上是比较包含元素数目不同的集合之间相似性

弹性匹配是一种采用动态时间变形（Dynamic Time Warp，DTW）技术的非线性匹配算法，已成功地运用于语音识别、签名认证和手写体识别等领域。

##### 动态时间规整：

一种衡量（长度不同）序列相似度的常见方法

![30](.\img\30.jpg)



##### 高斯聚类（Gaussian Clustering）

<img src=".\img\31.jpg" alt="31" style="zoom:50%;" />

##### 混合高斯聚类

更好地模拟同一类别中数据的差异性





#### 视频场景分析

**例子：足球比赛精彩场景提取**

![32](.\img\32.jpg)

##### 精彩场景提取步骤

- 提取压缩域音频特征
- 解说员兴奋解说识别
- 现场激昂欢呼声识别















